import os
os.environ["TORCH_HOME"] = "/mnt/afs/250010063/torch_cache"
import argparse
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.utils import make_grid, save_image
from tqdm import tqdm
from torchmetrics.image.fid import FrechetInceptionDistance
from models.vamp_flow import CrossFlowVampVAE
# ==============================================================================
# å¯¼å…¥æ¨¡å‹ (è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®)
# ==============================================================================


# ==============================================================================
# é…ç½®å‚æ•°
# ==============================================================================
def get_args():
    parser = argparse.ArgumentParser(description="Trainer for ResNet-Attention VampVAE")
    
    # å®éªŒåŸºç¡€é…ç½®
    parser.add_argument("--exp_name", type=str, default="ResVampVAE_CIFAR10", help="å®éªŒåç§°")
    parser.add_argument("--data_dir", type=str, default="/mnt/afs/250010063/DL4/data", help="æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--save_dir", type=str, default="/mnt/afs/250010063/DL4/result", help="ç»“æœä¿å­˜è·¯å¾„")
    parser.add_argument("--resume", type=str, default=r"", help="æ–­ç‚¹ç»­è®­è·¯å¾„ (last.pth)")
    parser.add_argument("--seed", type=int, default=42)
    
    # è®­ç»ƒè¶…å‚æ•°
    parser.add_argument("--epochs", type=int, default=1000, help="æ€» Epoch æ•°")
    parser.add_argument("--batch_size", type=int, default=128)
    parser.add_argument("--lr", type=float, default=1e-4, help="å­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=1e-4)
    
    # æ¨¡å‹å‚æ•° (å¿…é¡»ä¸å®šä¹‰ä¸€è‡´)
    parser.add_argument("--latent_dim", type=int, default=128)
    parser.add_argument("--num_components", type=int, default=100, help="VampPrior ä¼ªè¾“å…¥æ•°é‡")
    parser.add_argument("--img_size", type=int, default=32)
    
    # å…³é”®ç­–ç•¥
    parser.add_argument("--warmup_epochs", type=int, default=20, help="Beta é¢„çƒ­çš„ Epoch æ•°")
    parser.add_argument("--beta_max", type=float, default=0.2, help="KL æƒé‡æœ€å¤§å€¼")
    parser.add_argument("--grad_clip", type=float, default=1.0, help="æ¢¯åº¦è£å‰ª")
    
    # FID é…ç½®
    parser.add_argument("--fid_every", type=int, default=10, help="æ¯å¤šå°‘ Epoch æµ‹ä¸€æ¬¡ FID")
    parser.add_argument("--fid_samples", type=int, default=2000, help="æµ‹è¯• FID æ—¶ç”Ÿæˆçš„æ ·æœ¬æ•°")
    
    return parser.parse_args()

def set_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

# ==============================================================================
# è¾…åŠ©å‡½æ•°
# ==============================================================================

def visualize_pseudo_inputs(model, save_path, epoch):
    """
    å¯è§†åŒ– VampPrior å­¦åˆ°çš„ K ä¸ªä¼ªè¾“å…¥ã€‚
    è¿™äº›å›¾åƒä»£è¡¨äº† Latent Space ä¸­çš„ K ä¸ªâ€˜é”šç‚¹â€™ã€‚
    """
    model.eval()
    with torch.no_grad():
        # è·å–ä¼ªè¾“å…¥ [K, C, H, W]
        pseudo_imgs = model.embed_pseudo(model.pseudo_id).view(-1, *model.pseudo_img_shape)
        
        # åå½’ä¸€åŒ–: [-1, 1] -> [0, 1]
        vis_imgs = (pseudo_imgs + 1) / 2.0
        vis_imgs = torch.clamp(vis_imgs, 0, 1)
        
        # åªå–å‰ 64 ä¸ªå±•ç¤º
        n_show = min(64, model.num_components)
        grid = make_grid(vis_imgs[:n_show], nrow=8, padding=2)
        save_image((grid*255).to(torch.uint8), os.path.join(save_path, f"pseudo_epoch_{epoch}.png"))

@torch.no_grad()
def calculate_fid(model, dataloader, device, num_samples=2000):
    """
    è®¡ç®— FID åˆ†æ•°
    """
    model.eval()
    fid = FrechetInceptionDistance(feature=2048, normalize=False).to(device)
    
    print(f"--- Calculating FID ({num_samples} samples) ---")
    
    # 1. çœŸå®å›¾ç‰‡ç»Ÿè®¡ (Real)
    # éå†ä¸€éƒ¨åˆ†éªŒè¯é›†å³å¯
    count = 0
    for x, _ in dataloader:
        x = x.to(device)
        # Tanh [-1, 1] -> [0, 1]
        x = (x + 1) / 2.0
        x = x.clamp(0, 1)
        fid.update((x*255).to(torch.uint8), real=True)
        count += x.size(0)
        if count >= num_samples: break
            
    # 2. ç”Ÿæˆå›¾ç‰‡ç»Ÿè®¡ (Fake)
    # ä½¿ç”¨ VampVAE ç‰¹æœ‰çš„æ··åˆé‡‡æ ·
    remaining = num_samples
    while remaining > 0:
        batch = min(100, remaining)
        # æ³¨æ„: è¿™é‡Œçš„ sample ç­¾åæ˜¯ (num_samples, current_device)
        samples = model.sample(num_samples=batch, current_device=device)
        
        # Tanh [-1, 1] -> [0, 1]
        samples = (samples + 1) / 2.0
        samples = samples.clamp(0, 1)
        
        fid.update((samples*255).to(torch.uint8), real=False)
        remaining -= batch
        
    try:
        score = fid.compute().item()
        fid.reset()
        return score
    except Exception as e:
        print(f"FID Error: {e}")
        return float('inf')

@torch.no_grad()
def validate_loss(model, dataloader, device, beta):
    model.eval()
    total_loss = 0
    for x, _ in dataloader:
        x = x.to(device)
        results = model(x)
        # éªŒè¯æ—¶ä¹Ÿä¼ å…¥å½“å‰çš„ beta
        loss_dict = model.loss_function(*results, M_N=beta)
        total_loss += loss_dict['loss'].item()
    return total_loss / len(dataloader)

# ==============================================================================
# ä¸»è®­ç»ƒå¾ªç¯
# ==============================================================================
def train(args):
    set_seed(args.seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # è·¯å¾„è®¾ç½®
    exp_dir = os.path.join(args.save_dir, args.exp_name)
    sample_dir = os.path.join(exp_dir, "samples")
    os.makedirs(sample_dir, exist_ok=True)
    
    print(f"ğŸš€ Experiment: {args.exp_name}")
    print(f"ğŸ“‚ Saving to: {exp_dir}")

    # æ•°æ®é›† (å½’ä¸€åŒ–åˆ° -1, 1)
    transform = transforms.Compose([
        # transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
    
    # 3. å½’ä¸€åŒ– (ä¿æŒä¸å˜)
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])
    
    train_dataset = datasets.CIFAR10(root=args.data_dir, train=True, download=True, transform=train_transform)
    val_dataset = datasets.CIFAR10(root=args.data_dir, train=False, download=True, transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)

    
    model = CrossFlowVampVAE(
        in_channels=3,
        latent_dim=args.latent_dim,
        num_components=args.num_components,
        img_size=args.img_size,
        hidden_dims=[64, 128, 256, 512], # ResNet ç»“æ„å¯ä»¥æ›´æ·±
        flow_length=8,                 # å…³é”®ï¼šå¼€å¯ flow
        flow_embed_dim=args.latent_dim,
        flow_heads=4,
        device=device
    ).to(device)

    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)

    # History è®°å½•
    history = {
        "epoch": [], "train_loss": [], "val_loss": [], 
        "recon": [], "kld": [], "fid": [], "beta": [],'lpips':[]
    }
    
    
    start_epoch = 0
    best_fid = float('inf')
    
    # æ–­ç‚¹ç»­è®­
    if args.resume and os.path.exists(args.resume):
        print(f"â™»ï¸ Resuming from {args.resume}...")
        ckpt = torch.load(args.resume, map_location=device)
        model.load_state_dict(ckpt['model'])
        optimizer.load_state_dict(ckpt['optimizer'])
        scheduler.load_state_dict(ckpt['scheduler'])
        start_epoch = ckpt['epoch'] + 1
        best_fid = ckpt.get('best_fid', float('inf'))
        if 'history' in ckpt: history = ckpt['history']

    # --- Loop ---
    for epoch in range(start_epoch, args.epochs):
        model.train()
        progress_bar = tqdm(train_loader, desc=f"Ep {epoch+1}/{args.epochs}")
        
        epoch_loss = 0
        epoch_pixel = 0    # æ”¹å: åƒç´ æŸå¤±
        epoch_lpips = 0    # æ–°å¢: æ„ŸçŸ¥æŸå¤±
        epoch_kld_opt = 0  # å®é™…ä¼˜åŒ–çš„ KL
        epoch_kld_raw = 0  # çœŸå®çš„ KL (è§‚å¯Ÿæ˜¯å¦æœ‰ posterior collapse)
        
        # è®¡ç®—å½“å‰ Epoch çš„ Beta (Warmup)
        # ç®€å•çš„çº¿æ€§ Warmup: epoch 0 -> 0, epoch warmup -> beta_max
        beta_progress = min(1.0, epoch / max(1, args.warmup_epochs))
        current_beta = args.beta_max * beta_progress
        
        for x, _ in progress_bar:
            x = x.to(device)
            optimizer.zero_grad()
            
            #with torch.amp.autocast(device_type='cuda'):
            results = model(x)
            # results: [recons, input, mu, log_var, z]
            # æ³¨æ„ï¼šloss_function å‚æ•°åä¸º M_N è¡¨ç¤º beta
            loss_dict = model.loss_function(*results, M_N=current_beta)
            loss = loss_dict['loss']
            # optimizer.zero_grad(set_to_none=True)
            loss.backward()
            # scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            optimizer.step()

            # scaler.step(optimizer)
            # scaler.update()
            
            # --- æ›´æ–°ç»Ÿè®¡æ•°æ® ---
            # loss_dict çš„ key å¿…é¡»ä¸ loss_function è¿”å›çš„ä¸€è‡´
            epoch_loss += loss.item()
            epoch_pixel += loss_dict['Reconstruction_Loss'].item()
            epoch_lpips += loss_dict['LPIPS_Loss'].item()
            epoch_kld_opt += loss_dict['KLD_Optim'].item()
            epoch_kld_raw += loss_dict['KLD_Raw'].item()
            
            # --- è¿›åº¦æ¡æ‰“å° ---
            progress_bar.set_postfix({
                'L': f"{loss.item():.2f}",       # Total Loss
                'Pix': f"{loss_dict['Reconstruction_Loss'].item():.1f}", # Pixel L1
                'LPIPS': f"{loss_dict['LPIPS_Loss'].item():.3f}",        # é‡ç‚¹ç›‘æ§!
                'KL_R': f"{loss_dict['KLD_Raw'].item():.1f}",            # Raw KL
                'KL_O': f"{loss_dict['KLD_Optim'].item():.1f}"           # Optimized KL
            })

        # è®¡ç®—å¹³å‡å€¼
        avg_loss = epoch_loss / len(train_loader)
        avg_pixel = epoch_pixel / len(train_loader)
        avg_lpips = epoch_lpips / len(train_loader)
        avg_kld_opt = epoch_kld_opt / len(train_loader)
        avg_kld_raw = epoch_kld_raw / len(train_loader)
        
        
        # æ‰“å° Epoch æ€»ç»“
        
        # éªŒè¯é›† Loss
        val_loss = validate_loss(model, val_loader, device, current_beta)
        
        # FID è®¡ç®—
        fid_score = float('nan')
        if (epoch + 1) % args.fid_every == 0 or (epoch + 1) == args.epochs:
            fid_score = calculate_fid(model, val_loader, device, num_samples=args.fid_samples)
            if fid_score < best_fid:
                best_fid = fid_score
                save_dict = {
                'model': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'scheduler': scheduler.state_dict(),
                'epoch': epoch,
                'best_fid': best_fid,
                'history': history,
            }
                torch.save(save_dict, os.path.join(exp_dir, "best_fid.pth"))
                print(f"ğŸ”¥ New Best FID: {best_fid:.2f}")

        scheduler.step()
        
        # æ›´æ–° History (è¯·ç¡®ä¿ä½ åˆå§‹åŒ– history å­—å…¸æ—¶åŒ…å«äº†è¿™äº› key)
        # å»ºè®®åœ¨åˆå§‹åŒ– history æ—¶åŠ ä¸Š: "lpips": [], "kld_raw": []
        history['epoch'].append(epoch)
        history['train_loss'].append(avg_loss)
        history['val_loss'].append(val_loss)
        history['recon'].append(avg_pixel) # è®°å½•åƒç´ æŸå¤±
        history['lpips'].append(avg_lpips) # è®°å½• LPIPS
        history['kld'].append(avg_kld_raw) # è®°å½•åŸå§‹ KL æ›´èƒ½åæ˜ æ¨¡å‹çŠ¶æ€
        history['fid'].append(fid_score)
        history['beta'].append(current_beta)
        print(f"Ep {epoch+1} | Loss: {avg_loss:.2f} | LPIPS: {avg_lpips:.3f} | KL_Raw: {avg_kld_raw:.1f} | FID: {fid_score:.2f}")

        # ä¿å­˜ CSV
        pd.DataFrame(history).to_csv(os.path.join(exp_dir, "history.csv"), index=False)
        
        # å¯è§†åŒ–ä¸ä¿å­˜
        if (epoch + 1) % 5 == 0:
            # 1. é‡‡æ ·å›¾ç‰‡
            model.eval()
            with torch.no_grad():
                samples = model.sample(64, device)
                samples = (samples + 1) / 2.0 # åå½’ä¸€åŒ–
                samples = samples.clamp(0, 1)
                grid = make_grid((samples*255).to(torch.uint8), nrow=8, padding=2)
                save_image(grid, os.path.join(sample_dir, f"gen_epoch_{epoch}.png"), nrow=8)
            
            # 2. ä¼ªè¾“å…¥å¯è§†åŒ– (æŸ¥çœ‹ VampPrior çš„é”šç‚¹)
            visualize_pseudo_inputs(model, sample_dir, epoch)

        # ä¿å­˜ Last Checkpoint
        save_dict = {
            'model': model.state_dict(),
            'optimizer': optimizer.state_dict(),
            'scheduler': scheduler.state_dict(),
            'epoch': epoch,
            'best_fid': best_fid,
            'history': history,
        }
        torch.save(save_dict, os.path.join(exp_dir, "last.pth"))
        
        print(f"Epoch {epoch+1} | Loss: {avg_loss:.2f} | Val: {val_loss:.2f} | FID: {fid_score:.2f}")

if __name__ == "__main__":
    args = get_args()
    train(args)